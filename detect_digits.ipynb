{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb2a2a7",
   "metadata": {},
   "source": [
    "## import used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e07c5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f8e44",
   "metadata": {},
   "source": [
    "## Handy function for showing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b379c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(file, img):\n",
    "    cv2.imshow(file, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b647eeb",
   "metadata": {},
   "source": [
    "## Get images and initialze result with empty array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3576a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/train\" # path for the images in the data\n",
    "expected = \"./data.json\"\n",
    "margin_error = 10 # error when comparing bounding boxes\n",
    "files = [f for f in os.listdir(path) if f.endswith(\".png\")] # filter out only .png files in the given path\n",
    "cnt = len(files) - 1 # Run the algorithm on all the data, change this when testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef72cc",
   "metadata": {},
   "source": [
    "## Function to compute the iou between two bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b139dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(box1, box2):\n",
    "    # Compute the coordinates of the intersection rectangle\n",
    "    left = max(box1[\"left\"], box2[\"left\"])\n",
    "    top = max(box1[\"top\"], box2[\"top\"])\n",
    "    right = min(box1[\"left\"] + box1[\"width\"], box2[\"left\"] + box2[\"width\"])\n",
    "    bottom = min(box1[\"top\"] + box1[\"height\"], box2[\"top\"] + box2[\"height\"])\n",
    "\n",
    "    # If the intersection is empty, return 0\n",
    "    if right <= left or bottom <= top:\n",
    "        return 0.0\n",
    "\n",
    "    # Compute the area of the intersection and union rectangles\n",
    "    intersection = (right - left) * (bottom - top)\n",
    "    union = box1[\"width\"] * box1[\"height\"] + box2[\"width\"] * box2[\"height\"] - intersection\n",
    "\n",
    "    # Compute the IoU\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564f653",
   "metadata": {},
   "source": [
    "## Function to perform NMS on an array of boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "13d60a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, iou_threshold=0.4):\n",
    "    # Sort boxes by their confidence score (e.g., area)\n",
    "    boxes = sorted(boxes, key=lambda x: x[\"width\"] * x[\"height\"], reverse=True)\n",
    "\n",
    "    # Initialize a list of non-overlapping boxes\n",
    "    picked_boxes = []\n",
    "\n",
    "    # Loop over boxes\n",
    "    while boxes:\n",
    "        # Pick the box with the highest confidence score\n",
    "        picked_box = boxes.pop(0)\n",
    "        picked_boxes.append(picked_box)\n",
    "\n",
    "        # Compute the IoU between the picked box and all other boxes\n",
    "        iou_scores = [compute_iou(picked_box, box) for box in boxes]\n",
    "\n",
    "        # Remove all boxes with an IoU greater than the threshold\n",
    "        boxes = [boxes[i] for i in range(len(boxes)) if iou_scores[i] < iou_threshold]\n",
    "\n",
    "    return picked_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3170d8",
   "metadata": {},
   "source": [
    "## Detect digits using k-means clusetring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ac87c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering(img, boxes):\n",
    "    # Reshape the image to a 2D array of pixels and 3 color values (RGB)\n",
    "    pixel_values = img.reshape((-1, 3))\n",
    "    # Convert to float type\n",
    "    pixel_values = np.float32(pixel_values)\n",
    "\n",
    "    # Define the criteria for stopping the algorithm\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 0.2)\n",
    "\n",
    "    # Number of clusters (K)\n",
    "    k = 3\n",
    "    # Perform k-means clustering\n",
    "    _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 100, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Convert back to 8 bit values\n",
    "    centers = np.uint8(centers)\n",
    "\n",
    "    # Flatten the labels array\n",
    "    labels = labels.flatten()\n",
    "\n",
    "    # Convert all pixels to the color of the centroids\n",
    "    segmented_image = centers[labels]\n",
    "\n",
    "    # Reshape back to the original image dimension\n",
    "    segmented_image = segmented_image.reshape(img.shape)\n",
    "    \n",
    "    # Find the contours of the segments\n",
    "    gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Sharpen the image using the unsharp masking technique\n",
    "    blurred = cv2.GaussianBlur(gray, (0, 0), 3)\n",
    "    sharpened = cv2.addWeighted(gray, 1.5, blurred, -0.5, 0)\n",
    "            \n",
    "    thresh = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    inverted = 255 - thresh\n",
    "        \n",
    "    # Dilate to connect nearby contours\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "\n",
    "    # Erode to separate connected contours\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "       \n",
    "    contours, hierarchy = cv2.findContours(eroded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_inv, _ = cv2.findContours(inverted, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contours = contours + contours_inv\n",
    "    min_contour_area = 50\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > min_contour_area]\n",
    "    \n",
    "    # Define minimum and maximum aspect ratio for digits\n",
    "    min_aspect_ratio = 0.2\n",
    "    max_aspect_ratio = 2.5\n",
    "    \n",
    "    # Calculate image dimensions\n",
    "    img_height, img_width = img.shape[:2]\n",
    "\n",
    "\n",
    "    # Draw the bounding rectangle of each contour on the original image\n",
    "    for cnt in contours:\n",
    "        left,top,width,height = cv2.boundingRect(cnt)\n",
    "        \n",
    "        aspect_ratio = width / float(height)\n",
    "\n",
    "        # Filter out regions with aspect ratio outside the desired range\n",
    "        if aspect_ratio < min_aspect_ratio or aspect_ratio > max_aspect_ratio:\n",
    "            continue\n",
    "\n",
    "            \n",
    "        std_dev_threshold = 15\n",
    "        std_dev = cv2.meanStdDev(\n",
    "            gray[top:top+height, left:left+width])[1][0][0]\n",
    "        if std_dev < std_dev_threshold:\n",
    "            continue\n",
    "            \n",
    "        # Define minimum and maximum dimensions for digits\n",
    "        minWidth = int(0.02 * img_width)\n",
    "        minHeight = int(0.02 * img_height)\n",
    "        maxWidth = int(0.5 * img_width)\n",
    "        maxHeight = int(0.95 * img_height)\n",
    "        \n",
    "        # filter out too small or too big objects that are not likely to contain digits\n",
    "        if width < minWidth or height < minHeight or width > maxWidth or height > maxHeight:\n",
    "            continue\n",
    "                       \n",
    "        # Append bounding box to list\n",
    "        boxes.append({\n",
    "            \"label\": 0,\n",
    "            \"left\": left,\n",
    "            \"top\": top,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })        \n",
    "        \n",
    "    # Append results for current file to overall results\n",
    "    results.append({\n",
    "        \"filename\": file[len(path)+1:],\n",
    "        \"boxes\": boxes\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b35108",
   "metadata": {},
   "source": [
    "## Loop on dataset images to test the algorithms\n",
    "\n",
    "Note: you can uncomment the show(file, img) command to see the ouput image of the algorithm but before doing that consider changing the cnt because it will perform the algorithm on the whole dataset which takes alot of time so for testing using a cnt of 10 is sufficient to see a sample output of the algorithm instead of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a7b26a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open(expected) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "for i in range(cnt):\n",
    "    file = f'{path}/{files[i]}'\n",
    "    # Read the image\n",
    "    img = cv2.imread(file)\n",
    "    boxes = []    \n",
    "    k_means_clustering(img, boxes)\n",
    "    filtered_boxes = non_max_suppression(boxes)\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(img,(box[\"left\"], box[\"top\"]),(box[\"left\"] + box[\"width\"], box[\"top\"] + box[\"height\"]),(0,0,255),1)\n",
    "        \n",
    "#     show(file, img)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# Save the data\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Close cv2 windows if any are open\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168453e",
   "metadata": {},
   "source": [
    "## Test algorithm accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cf645f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm accuracy: 59.92%\n"
     ]
    }
   ],
   "source": [
    "def test(file, i, correct, actual):\n",
    "    expected = data[int(file[:-4]) - 1]\n",
    "    res = results[i]\n",
    "    actual[0] += len(expected[\"boxes\"])\n",
    "    # loop over all the boxes in the expected data and see if any matches\n",
    "    # the boxes generated by the algorithm\n",
    "    for exp in expected[\"boxes\"]:\n",
    "        seen = False\n",
    "        for box in res[\"boxes\"]:\n",
    "            if abs(box[\"left\"] - exp[\"left\"]) <= margin_error \\\n",
    "            and abs(box[\"top\"] - exp[\"top\"]) <= margin_error \\\n",
    "            and abs(box[\"width\"] - exp[\"width\"]) <= margin_error \\\n",
    "            and abs(box[\"height\"] - exp[\"height\"]) <= margin_error:\n",
    "                seen = True\n",
    "        correct[0] += seen\n",
    "\n",
    "\n",
    "            \n",
    "correct_boxes = [0]\n",
    "actual_boxes = [0]\n",
    "\n",
    "for i in range(cnt):\n",
    "    file = files[i]\n",
    "    test(file, i, correct_boxes, actual_boxes)\n",
    "        \n",
    "print(f\"Algorithm accuracy: {round(((correct_boxes[0]/actual_boxes[0]) * 100), 2)}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c1e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
