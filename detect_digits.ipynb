{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb2a2a7",
   "metadata": {},
   "source": [
    "## import used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e07c5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f8e44",
   "metadata": {},
   "source": [
    "## Handy function for showing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b379c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(file, img):\n",
    "    cv2.imshow(file, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b647eeb",
   "metadata": {},
   "source": [
    "## Get images and initialze result with empty array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3576a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/train\"\n",
    "expected = \"./data/data.json\"\n",
    "margin_error = 10\n",
    "files = [f for f in os.listdir(path) if f.endswith(\".png\")]\n",
    "cnt = 2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499fe3c",
   "metadata": {},
   "source": [
    "## Define the Algorithm to detect digits using contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc34bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digits(file, boxes):\n",
    "    # Load the image and convert to grayscale\n",
    "    img = cv2.imread(file)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Increase image contrast using histogram equalization\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    # Sharpen the image using the unsharp masking technique\n",
    "    blurred = cv2.GaussianBlur(gray, (0, 0), 3)\n",
    "    sharpened = cv2.addWeighted(gray, 1.5, blurred, -0.5, 0)\n",
    "    \n",
    "    # Apply adaptive thresholding to the image\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        sharpened, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    inverted = 255 - binary\n",
    "    \n",
    "    # Apply Canny edge detection to the binary image\n",
    "    edges = cv2.Canny(binary, 100, 200)\n",
    "\n",
    "    # Find contours of the digits\n",
    "    contours, _ = cv2.findContours(\n",
    "        binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_inv, _ = cv2.findContours(\n",
    "        inverted, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "       # Filter out small contours\n",
    "    min_contour_area = 50\n",
    "    contours = [c for c in contours if cv2.contourArea(\n",
    "        c) > min_contour_area] + [c for c in contours_inv if cv2.contourArea(c) > min_contour_area]\n",
    "    \n",
    "        # Define minimum and maximum aspect ratio for digits\n",
    "    min_aspect_ratio = 0.2\n",
    "    max_aspect_ratio = 2.5\n",
    "     # Draw bounding boxes around the regions that are likely to contain digits\n",
    "    for contour in contours:\n",
    "        left, top, width, height = cv2.boundingRect(contour)\n",
    "\n",
    "        aspect_ratio = width / float(height)\n",
    "\n",
    "        # Filter out regions with aspect ratio outside the desired range\n",
    "        if aspect_ratio < min_aspect_ratio or aspect_ratio > max_aspect_ratio:\n",
    "            continue\n",
    "\n",
    "        std_dev_threshold = 4\n",
    "        std_dev = cv2.meanStdDev(\n",
    "            gray[top:top+height, left:left+width])[1][0][0]\n",
    "        if std_dev < std_dev_threshold:\n",
    "            continue\n",
    "            \n",
    "\n",
    "        # Calculate image dimensions\n",
    "        img_height, img_width = img.shape[:2]\n",
    "        \n",
    "        # The digits is likely to be in the middle of the image so filter out contours on the far edges\n",
    "        if (left < int(0.1 * img_width)) or ((left + width) > int(0.9 * img_width)):\n",
    "            continue\n",
    "\n",
    "        # Define minimum and maximum dimensions for digits\n",
    "        minWidth = int(0.04 * img_width)\n",
    "        minHeight = int(0.04 * img_height)\n",
    "        maxWidth = int(0.27 * img_width)\n",
    "        maxHeight = int(0.95 * img_height)\n",
    "        \n",
    "\n",
    "        if width < minWidth or height < minHeight or width > maxWidth or height > maxHeight:\n",
    "            continue\n",
    "            \n",
    "        # Append bounding box to list\n",
    "        boxes.append({\n",
    "            \"label\": 0,\n",
    "            \"left\": left,\n",
    "            \"top\": top,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "            \n",
    "        # Draw bounding boxes around the regions that are likely to contain digits\n",
    "        cv2.rectangle(img, (left, top), (left + width,\n",
    "                      top + height), (0, 0, 255), 1)\n",
    "\n",
    "    # Display the image with bounding boxes around the digits\n",
    "#     show(file, img)\n",
    "\n",
    "    # Append results for current file to overall results\n",
    "    results.append({\n",
    "        \"filename\": file[len(path)+1:],\n",
    "        \"boxes\": boxes\n",
    "    })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3170d8",
   "metadata": {},
   "source": [
    "## Define the algorithm to detect digits using k-means clusetring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac87c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering(file, boxes):\n",
    "    # Read the image\n",
    "    img = cv2.imread(file)\n",
    "\n",
    "    # Reshape the image to a 2D array of pixels and 3 color values (RGB)\n",
    "    pixel_values = img.reshape((-1, 3))\n",
    "    # Convert to float type\n",
    "    pixel_values = np.float32(pixel_values)\n",
    "\n",
    "    # Define the criteria for stopping the algorithm\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 0.2)\n",
    "\n",
    "    # Number of clusters (K)\n",
    "    k = 3\n",
    "    # Perform k-means clustering\n",
    "    _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 100, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Convert back to 8 bit values\n",
    "    centers = np.uint8(centers)\n",
    "\n",
    "    # Flatten the labels array\n",
    "    labels = labels.flatten()\n",
    "\n",
    "    # Convert all pixels to the color of the centroids\n",
    "    segmented_image = centers[labels]\n",
    "\n",
    "    # Reshape back to the original image dimension\n",
    "    segmented_image = segmented_image.reshape(img.shape)\n",
    "    \n",
    "    # Find the contours of the segments\n",
    "    gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    equ = cv2.equalizeHist(gray)\n",
    "\n",
    "\n",
    "    # Sharpen the image using the unsharp masking technique\n",
    "    blurred = cv2.GaussianBlur(gray, (0, 0), 3)\n",
    "    sharpened = cv2.addWeighted(gray, 1.5, blurred, -0.5, 0)\n",
    "        \n",
    "\n",
    "#     ret, thresh = cv2.threshold(sharpened, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    thresh = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "#     show(file, thresh)\n",
    "    inverted = 255 - thresh\n",
    "    \n",
    "    \n",
    "    # Dilate to connect nearby contours\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "\n",
    "    # Erode to separate connected contours\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "    \n",
    "#     show(file, eroded)\n",
    "   \n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_inv, _ = cv2.findContours(inverted, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "#     contours = contours + contours_inv\n",
    "    \n",
    "    min_contour_area = 50\n",
    "#     contours = [c for c in contours if cv2.contourArea(\n",
    "#         c) > min_contour_area] + [c for c in contours_inv if cv2.contourArea(c) > min_contour_area]\n",
    "    \n",
    "    # Define minimum and maximum aspect ratio for digits\n",
    "    min_aspect_ratio = 0.2\n",
    "    max_aspect_ratio = 2.5\n",
    "\n",
    "\n",
    "    # Draw the bounding rectangle of each contour on the original image\n",
    "    for cnt in contours:\n",
    "        left,top,width,height = cv2.boundingRect(cnt)\n",
    "        \n",
    "        aspect_ratio = width / float(height)\n",
    "\n",
    "        # Filter out regions with aspect ratio outside the desired range\n",
    "        if aspect_ratio < min_aspect_ratio or aspect_ratio > max_aspect_ratio:\n",
    "            continue\n",
    "\n",
    "            \n",
    "        std_dev_threshold = 15\n",
    "        std_dev = cv2.meanStdDev(\n",
    "            gray[top:top+height, left:left+width])[1][0][0]\n",
    "        if std_dev < std_dev_threshold:\n",
    "            continue\n",
    "        # Calculate image dimensions\n",
    "        img_height, img_width = img.shape[:2]\n",
    "\n",
    "        # Define minimum and maximum dimensions for digits\n",
    "        minWidth = int(0.04 * img_width)\n",
    "        minHeight = int(0.04 * img_height)\n",
    "        maxWidth = int(0.5 * img_width)\n",
    "        maxHeight = int(0.95 * img_height)\n",
    "        \n",
    "\n",
    "        if width < minWidth or height < minHeight or width > maxWidth or height > maxHeight:\n",
    "            continue\n",
    "                       \n",
    "        # Append bounding box to list\n",
    "        boxes.append({\n",
    "            \"label\": 0,\n",
    "            \"left\": left,\n",
    "            \"top\": top,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "        cv2.rectangle(img,(left, top),(left + width, top + height),(0,0,255),1)\n",
    "        \n",
    "        \n",
    "    # Append results for current file to overall results\n",
    "    results.append({\n",
    "        \"filename\": file[len(path)+1:],\n",
    "        \"boxes\": boxes\n",
    "    })\n",
    "\n",
    "\n",
    "    # Show the image with bounding rectangles\n",
    "#     show(file, img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b35108",
   "metadata": {},
   "source": [
    "## Loop on some files to test the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7b26a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "rand_files = []\n",
    "random.shuffle(files)\n",
    "with open(expected) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "for i in range(cnt):\n",
    "#     r = random.randint(1, 33402)\n",
    "    file = f'{path}/{files[i]}'\n",
    "#     rand_files.append(r)\n",
    "    boxes = []    \n",
    "    k_means_clustering(file, boxes)\n",
    "#     detect_digits(file, boxes)\n",
    "    \n",
    "# Display the image with bounding boxes around the digits\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168453e",
   "metadata": {},
   "source": [
    "## Test algorithm accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf645f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586 1078\n",
      "Algorithm accuracy: 54.35992578849722%\n"
     ]
    }
   ],
   "source": [
    "def test(file, i, correct, actual):\n",
    "    expected = data[int(file[:-4]) - 1]\n",
    "    res = results[i]\n",
    "    actual[0] += len(expected[\"boxes\"])\n",
    "    \n",
    "\n",
    "    for exp in expected[\"boxes\"]:\n",
    "        seen = False\n",
    "        for box in res[\"boxes\"]:\n",
    "            if abs(box[\"left\"] - exp[\"left\"]) <= margin_error \\\n",
    "            and abs(box[\"top\"] - exp[\"top\"]) <= margin_error \\\n",
    "            and abs(box[\"width\"] - exp[\"width\"]) <= margin_error \\\n",
    "            and abs(box[\"height\"] - exp[\"height\"]) <= margin_error:\n",
    "                seen = True\n",
    "        correct[0] += seen\n",
    "\n",
    "\n",
    "            \n",
    "correct_boxes = [0]\n",
    "actual_boxes = [0]\n",
    "\n",
    "for i in range(cnt):\n",
    "    file = files[i]\n",
    "    test(file, i, correct_boxes, actual_boxes)\n",
    "\n",
    "print(correct_boxes[0], actual_boxes[0])\n",
    "        \n",
    "print(f\"Algorithm accuracy: {(correct_boxes[0]/actual_boxes[0]) * 100}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04243ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
